{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi-tpRGfQBoR",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcJ8jcTpQyuK",
        "colab_type": "code",
        "outputId": "ea6fe861-9160-4b14-cd64-719726784841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "!pip install scikit-video"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/a6/c69cad508139a342810ae46e946ebb3256aa6e42f690d901bb68f50582e3/scikit_video-1.1.11-py2.py3-none-any.whl (2.3MB)\n",
            "\r\u001b[K     |▏                               | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 1.8MB/s eta 0:00:02\r\u001b[K     |▍                               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 1.7MB/s eta 0:00:02\r\u001b[K     |▊                               | 51kB 2.1MB/s eta 0:00:02\r\u001b[K     |▉                               | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▏                           | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 696kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 727kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 757kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 829kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 860kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 890kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 962kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 993kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.6MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.9MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 2.2MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from scikit-video) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-video) (1.17.5)\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzp26K4iRLEN",
        "colab_type": "code",
        "outputId": "87a65581-2b76-45fb-f308-ec6637d94721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avHfHHUGQBol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "e59661f9-40b1-4e03-aff3-14291f38e921"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "import random\n",
        "import copy\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, Conv1D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly8D9whLQBpl",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cqG-Qr8QBpw",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DRxjIVoQBp5",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_anhgjtKQBqI",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hsn_byKOQBqO",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN6HV5s9QBqa",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHxXBxJzQBqv",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddOPGAd5QBq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCWLVokpQBra",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dte3S9ABQBrn",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXnDWUUXQBru",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgRQ8kimQBr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def reduce_epsilon(self, r):\n",
        "        self.epsilon *= r \n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu8Q-nghQBsN",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79TG6nE7QBsp",
        "colab_type": "text"
      },
      "source": [
        "```epsilon``` is meant to introduce randomness in the model. If the end result is higher with ```epsilon``` > 0 than ```epsilon``` = 0, the learned act model can be improved. This is called the epsilon-greedy algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuyIf-JnQBs1",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEtTgS2mQBtB",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTjrG2f9QBtI",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvQ7YxCDQBtQ",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRNI_K92QBtX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        #I changed the following line\n",
        "        self.position[:,-2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        #I changed the following line\n",
        "        self.position[:, -2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNLRjq7cQBtz",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X06hFKE8QBt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=100 # set small when debugging\n",
        "epochs_test=10 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NtVRf78QBuY",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er8Mpx2hQBul",
        "colab_type": "text"
      },
      "source": [
        "```position``` represents the mouse's position with -1 for the borders, 1 where is the mouse and 0 the rest.\n",
        "```board``` represents what the mouse can win."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05IBf0nuQBuq",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h5SkHhVQBu1",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgQFK5IlQBu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "      return random.randint(0,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMiQ7QySQBvV",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faEDED3aQBvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "              \n",
        "      state = env.reset()\n",
        "      # This assumes that the games will end\n",
        "      game_over = False\n",
        "  \n",
        "      win = 0\n",
        "      lose = 0\n",
        "  \n",
        "      while not game_over:\n",
        "\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "  \n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "  \n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "        \n",
        "      # Save as a mp4\n",
        "      env.draw(prefix+str(e))\n",
        "\n",
        "      # Update stats\n",
        "      score = score + win-lose\n",
        "\n",
        "      print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "            .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzzCLFIlQBv8",
        "colab_type": "code",
        "outputId": "e9200709-d458-4383-d7e2-feb84f3c901c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 8.0/8.0. Average score (0.0)\n",
            "Win/lose count 11.0/18.0. Average score (-3.5)\n",
            "Win/lose count 12.5/10.0. Average score (-1.5)\n",
            "Win/lose count 3.5/11.0. Average score (-3.0)\n",
            "Win/lose count 7.0/6.0. Average score (-2.2)\n",
            "Win/lose count 12.0/11.0. Average score (-1.6666666666666667)\n",
            "Win/lose count 5.0/16.0. Average score (-3.0)\n",
            "Win/lose count 11.0/18.0. Average score (-3.5)\n",
            "Win/lose count 9.5/20.0. Average score (-4.277777777777778)\n",
            "Win/lose count 11.5/12.0. Average score (-3.9)\n",
            "Final score: -3.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4fUDrDQQBwY",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmaLExmsQBwq",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, by definition\n",
        "\n",
        "$Q^{\\pi}(s,a)= E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\>$\n",
        "\n",
        "Then,\n",
        "\n",
        "$Q^{\\pi}(s,a)= E_{p^{\\pi}}[\\sum_{1\\leq t \\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] + r(s, a)$\n",
        "\n",
        "Since $\\gamma^{t} r(s_{t},a_{t})$ admits a first moment in $s_{0}=s,a_{0}=a$ space, we can write :\n",
        "\n",
        "$ E_{p^{\\pi}}[\\sum_{1\\leq t \\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] = \\gamma E_{(s',a')\\sim p(.|s,a)}[\\sum_{t \\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s',a_{0}=a']$\n",
        "\n",
        "Thus,\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Let's assume there is an optimal policy $\\pi^*$. By definition:\n",
        "\n",
        "$Q^{*}(s,a)=\\max_{\\pi}Q^\\pi(s,a) = Q^{\\pi^*}(s,a)$\n",
        "\n",
        "Then\n",
        "\n",
        "$Q^{*}(s,a) = \\max_{\\pi} E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]$\n",
        "\n",
        "And\n",
        "\n",
        "$Q^{*}(s,a) = E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma \\max_{\\pi}Q^{\\pi}(s',a')]$\n",
        "\n",
        "Since $\\pi^*$ is a deterministic policy, $\\pi^*(a') = s'$ and we can write\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Finally, let's suppose that\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "which is a plausible objective because\n",
        "\n",
        "$\\mathcal{L}(\\theta)=Var_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2} + (E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert)^{2}$\n",
        "\n",
        "or according to the equation above\n",
        "\n",
        "$\\mathcal{L}(\\theta)=Var_{s' \\sim \\pi^*(.|s,a)}\\Vert Q^*(s,a,\\theta)-Q(s,a,\\theta))\\Vert^{2} + (E_{s' \\sim \\pi^*(.|s,a)}\\Vert Q^*(s,a,\\theta)-Q(s,a,\\theta)\\Vert)^{2}$\n",
        "\n",
        "i.e\n",
        "\n",
        "$\\mathcal{L}(\\theta)=Var_{s' \\sim \\pi^*(.|s,a)}\\Vert Q^*(s,a,\\theta)-Q(s,a,\\theta))\\Vert^{2} + (bias(Q(s,a,\\theta)))^{2}$\n",
        "\n",
        "This loss function tends to minimize the bias and volatility between empirical and optimal policy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OauNhfUQBw7",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QH62t3CQBxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "      #we check if there is enough memory\n",
        "      if len(self.memory) < self.max_memory:\n",
        "        self.memory.append(m)\n",
        "      #if the memory is full, we add m at the beginning (like a stack)\n",
        "      else:\n",
        "        self.memory = [m] +  self.memory[1:]\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[random.randint(0,len(self.memory)-1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCr1An11QBxc",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogq0QrA4QBxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state, train=True)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQZo6jC6QByK",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxexl7nWQByS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.8\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(np.expand_dims(s,0))[0])\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "          \n",
        "          #we get a previous memory\n",
        "          s, ns, a, r, game_over = self.memory.random_access()\n",
        "          \n",
        "          #we stock the old state to train the model\n",
        "          input_states[i] = s\n",
        "          \n",
        "          if game_over_:\n",
        "              #we predict the reward after the new state\n",
        "              target = self.model.predict(np.expand_dims(ns,0))\n",
        "              #if it lead to game over we do not actualize for this action\n",
        "              target[0][a] = r\n",
        "          else:\n",
        "              target = self.model.predict(np.expand_dims(ns,0))\n",
        "              #we follow the same idea as in Q5\n",
        "              target[0][a] = r + self.discount*max(target[0])\n",
        "          \n",
        "          #we stock the actualized reward\n",
        "          target_q[i]  = target[0]\n",
        "        \n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "        \n",
        "        #we train the lodel by batch\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model with 5 layers\n",
        "        model = Sequential([\n",
        "            Dense(4,  input_shape=(5,5,self.n_state)),\n",
        "            Activation('relu'),\n",
        "            Dense(4),\n",
        "            Activation('relu'),\n",
        "            Dense(4),\n",
        "            Activation('relu'),\n",
        "            Dense(4),\n",
        "            Activation('relu'),\n",
        "            keras.layers.Flatten(),\n",
        "            Dense(4),\n",
        "            Activation('linear'),\n",
        "        ])\n",
        "        \n",
        "        #model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        model.compile(keras.optimizers.RMSprop(lr=lr), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baIWO9TKmOU7",
        "colab_type": "code",
        "outputId": "8350cf02-dd57-42f0-d776-137e0347a167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=0.001, epsilon = 0.2, memory_size=2000, batch_size = 30)\n",
        "train(agent, env, 100, prefix='fc_train')\n",
        "HTML(display_videos('fc_train10.mp4'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 000/100 | Loss 0.0119 | Win/lose count 6.5/6.0 (0.5)\n",
            "Epoch 001/100 | Loss 0.0085 | Win/lose count 11.0/7.0 (4.0)\n",
            "Epoch 002/100 | Loss 0.0165 | Win/lose count 8.0/8.0 (0.0)\n",
            "Epoch 003/100 | Loss 0.0064 | Win/lose count 3.5/10.0 (-6.5)\n",
            "Epoch 004/100 | Loss 0.0066 | Win/lose count 6.5/13.0 (-6.5)\n",
            "Epoch 005/100 | Loss 0.0134 | Win/lose count 10.0/12.0 (-2.0)\n",
            "Epoch 006/100 | Loss 0.0213 | Win/lose count 9.0/8.0 (1.0)\n",
            "Epoch 007/100 | Loss 0.0026 | Win/lose count 13.0/10.0 (3.0)\n",
            "Epoch 008/100 | Loss 0.0071 | Win/lose count 16.5/11.0 (5.5)\n",
            "Epoch 009/100 | Loss 0.0069 | Win/lose count 10.0/5.0 (5.0)\n",
            "Epoch 010/100 | Loss 0.0102 | Win/lose count 17.5/10.0 (7.5)\n",
            "Epoch 011/100 | Loss 0.0352 | Win/lose count 14.0/5.0 (9.0)\n",
            "Epoch 012/100 | Loss 0.0138 | Win/lose count 18.0/10.0 (8.0)\n",
            "Epoch 013/100 | Loss 0.0473 | Win/lose count 21.0/10.0 (11.0)\n",
            "Epoch 014/100 | Loss 0.0335 | Win/lose count 12.0/2.0 (10.0)\n",
            "Epoch 015/100 | Loss 0.0331 | Win/lose count 5.5/5.0 (0.5)\n",
            "Epoch 016/100 | Loss 0.0312 | Win/lose count 17.5/4.0 (13.5)\n",
            "Epoch 017/100 | Loss 0.0311 | Win/lose count 10.5/3.0 (7.5)\n",
            "Epoch 018/100 | Loss 0.0268 | Win/lose count 13.5/4.0 (9.5)\n",
            "Epoch 019/100 | Loss 0.0207 | Win/lose count 14.0/3.0 (11.0)\n",
            "Epoch 020/100 | Loss 0.0506 | Win/lose count 18.0/8.0 (10.0)\n",
            "Epoch 021/100 | Loss 0.0415 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 022/100 | Loss 0.0245 | Win/lose count 6.5/7.0 (-0.5)\n",
            "Epoch 023/100 | Loss 0.0431 | Win/lose count 12.0/4.0 (8.0)\n",
            "Epoch 024/100 | Loss 0.0267 | Win/lose count 16.0/6.0 (10.0)\n",
            "Epoch 025/100 | Loss 0.0743 | Win/lose count 15.0/3.0 (12.0)\n",
            "Epoch 026/100 | Loss 0.0278 | Win/lose count 24.0/3.0 (21.0)\n",
            "Epoch 027/100 | Loss 0.0387 | Win/lose count 18.0/3.0 (15.0)\n",
            "Epoch 028/100 | Loss 0.0781 | Win/lose count 10.5/6.0 (4.5)\n",
            "Epoch 029/100 | Loss 0.0596 | Win/lose count 17.0/7.0 (10.0)\n",
            "Epoch 030/100 | Loss 0.0324 | Win/lose count 13.5/4.0 (9.5)\n",
            "Epoch 031/100 | Loss 0.0395 | Win/lose count 14.0/1.0 (13.0)\n",
            "Epoch 032/100 | Loss 0.0352 | Win/lose count 14.0/7.0 (7.0)\n",
            "Epoch 033/100 | Loss 0.0635 | Win/lose count 17.5/8.0 (9.5)\n",
            "Epoch 034/100 | Loss 0.0554 | Win/lose count 18.5/2.0 (16.5)\n",
            "Epoch 035/100 | Loss 0.0292 | Win/lose count 16.0/1.0 (15.0)\n",
            "Epoch 036/100 | Loss 0.0437 | Win/lose count 19.5/1.0 (18.5)\n",
            "Epoch 037/100 | Loss 0.0587 | Win/lose count 12.0/5.0 (7.0)\n",
            "Epoch 038/100 | Loss 0.0723 | Win/lose count 16.5/6.0 (10.5)\n",
            "Epoch 039/100 | Loss 0.0545 | Win/lose count 21.0/10.0 (11.0)\n",
            "Epoch 040/100 | Loss 0.0286 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 041/100 | Loss 0.0296 | Win/lose count 16.0/4.0 (12.0)\n",
            "Epoch 042/100 | Loss 0.0549 | Win/lose count 9.5/5.0 (4.5)\n",
            "Epoch 043/100 | Loss 0.0348 | Win/lose count 14.0/5.0 (9.0)\n",
            "Epoch 044/100 | Loss 0.0362 | Win/lose count 17.5/4.0 (13.5)\n",
            "Epoch 045/100 | Loss 0.0578 | Win/lose count 17.0/8.0 (9.0)\n",
            "Epoch 046/100 | Loss 0.0320 | Win/lose count 20.0/6.0 (14.0)\n",
            "Epoch 047/100 | Loss 0.0543 | Win/lose count 15.5/5.0 (10.5)\n",
            "Epoch 048/100 | Loss 0.0475 | Win/lose count 11.5/5.0 (6.5)\n",
            "Epoch 049/100 | Loss 0.0621 | Win/lose count 15.5/3.0 (12.5)\n",
            "Epoch 050/100 | Loss 0.0272 | Win/lose count 15.0/4.0 (11.0)\n",
            "Epoch 051/100 | Loss 0.0462 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 052/100 | Loss 0.0376 | Win/lose count 12.0/4.0 (8.0)\n",
            "Epoch 053/100 | Loss 0.0424 | Win/lose count 17.5/2.0 (15.5)\n",
            "Epoch 054/100 | Loss 0.0339 | Win/lose count 21.0/3.0 (18.0)\n",
            "Epoch 055/100 | Loss 0.0532 | Win/lose count 5.5/6.0 (-0.5)\n",
            "Epoch 056/100 | Loss 0.0415 | Win/lose count 20.0/6.0 (14.0)\n",
            "Epoch 057/100 | Loss 0.0282 | Win/lose count 16.0/5.0 (11.0)\n",
            "Epoch 058/100 | Loss 0.0494 | Win/lose count 18.0/4.0 (14.0)\n",
            "Epoch 059/100 | Loss 0.0272 | Win/lose count 17.0/2.0 (15.0)\n",
            "Epoch 060/100 | Loss 0.0340 | Win/lose count 22.5/4.0 (18.5)\n",
            "Epoch 061/100 | Loss 0.0659 | Win/lose count 25.0/7.0 (18.0)\n",
            "Epoch 062/100 | Loss 0.0369 | Win/lose count 16.0/8.0 (8.0)\n",
            "Epoch 063/100 | Loss 0.0430 | Win/lose count 6.5/2.0 (4.5)\n",
            "Epoch 064/100 | Loss 0.0406 | Win/lose count 17.5/5.0 (12.5)\n",
            "Epoch 065/100 | Loss 0.0646 | Win/lose count 20.0/3.0 (17.0)\n",
            "Epoch 066/100 | Loss 0.0622 | Win/lose count 12.0/8.0 (4.0)\n",
            "Epoch 067/100 | Loss 0.0436 | Win/lose count 12.0/3.0 (9.0)\n",
            "Epoch 068/100 | Loss 0.0327 | Win/lose count 7.0/3.0 (4.0)\n",
            "Epoch 069/100 | Loss 0.0277 | Win/lose count 16.0/5.0 (11.0)\n",
            "Epoch 070/100 | Loss 0.0401 | Win/lose count 13.5/4.0 (9.5)\n",
            "Epoch 071/100 | Loss 0.0259 | Win/lose count 15.0/7.0 (8.0)\n",
            "Epoch 072/100 | Loss 0.0267 | Win/lose count 19.0/4.0 (15.0)\n",
            "Epoch 073/100 | Loss 0.0268 | Win/lose count 12.5/7.0 (5.5)\n",
            "Epoch 074/100 | Loss 0.0479 | Win/lose count 15.0/6.0 (9.0)\n",
            "Epoch 075/100 | Loss 0.0389 | Win/lose count 12.5/5.0 (7.5)\n",
            "Epoch 076/100 | Loss 0.0421 | Win/lose count 11.0/4.0 (7.0)\n",
            "Epoch 077/100 | Loss 0.0510 | Win/lose count 14.0/3.0 (11.0)\n",
            "Epoch 078/100 | Loss 0.0342 | Win/lose count 17.5/3.0 (14.5)\n",
            "Epoch 079/100 | Loss 0.0356 | Win/lose count 7.5/2.0 (5.5)\n",
            "Epoch 080/100 | Loss 0.0530 | Win/lose count 15.5/4.0 (11.5)\n",
            "Epoch 081/100 | Loss 0.0705 | Win/lose count 8.0/9.0 (-1.0)\n",
            "Epoch 082/100 | Loss 0.0648 | Win/lose count 9.0/5.0 (4.0)\n",
            "Epoch 083/100 | Loss 0.0602 | Win/lose count 13.0/5.0 (8.0)\n",
            "Epoch 084/100 | Loss 0.0448 | Win/lose count 16.0/5.0 (11.0)\n",
            "Epoch 085/100 | Loss 0.0279 | Win/lose count 6.5/1.0 (5.5)\n",
            "Epoch 086/100 | Loss 0.0205 | Win/lose count 9.5/4.0 (5.5)\n",
            "Epoch 087/100 | Loss 0.0471 | Win/lose count 17.5/6.0 (11.5)\n",
            "Epoch 088/100 | Loss 0.0315 | Win/lose count 21.5/6.0 (15.5)\n",
            "Epoch 089/100 | Loss 0.0421 | Win/lose count 13.0/6.0 (7.0)\n",
            "Epoch 090/100 | Loss 0.0416 | Win/lose count 11.0/4.0 (7.0)\n",
            "Epoch 091/100 | Loss 0.0375 | Win/lose count 14.0/8.0 (6.0)\n",
            "Epoch 092/100 | Loss 0.0265 | Win/lose count 18.5/11.0 (7.5)\n",
            "Epoch 093/100 | Loss 0.0251 | Win/lose count 17.0/8.0 (9.0)\n",
            "Epoch 094/100 | Loss 0.0588 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 095/100 | Loss 0.0615 | Win/lose count 15.5/2.0 (13.5)\n",
            "Epoch 096/100 | Loss 0.0433 | Win/lose count 12.0/3.0 (9.0)\n",
            "Epoch 097/100 | Loss 0.0670 | Win/lose count 16.0/4.0 (12.0)\n",
            "Epoch 098/100 | Loss 0.0516 | Win/lose count 9.5/4.0 (5.5)\n",
            "Epoch 099/100 | Loss 0.0348 | Win/lose count 16.5/6.0 (10.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrXTrPUGQBzE",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRsNjVMSQBzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        model = Sequential([\n",
        "            \n",
        "            Conv2D(32, kernel_size=(2,2), padding=\"same\"),\n",
        "            Activation('relu'),\n",
        "            Conv2D(32, kernel_size=(2,2), padding=\"same\"),\n",
        "            Activation('relu'),\n",
        "            Conv2D(16, kernel_size=(2,2)),\n",
        "            Activation('relu'),\n",
        "            keras.layers.Flatten(),\n",
        "            Dense(4),\n",
        "            Activation('softmax')\n",
        "        ])\n",
        "        \n",
        "        model.compile(keras.optimizers.RMSprop(lr=lr), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et84_-KcQBzz",
        "colab_type": "code",
        "outputId": "96d30796-7d1c-4e22-a1f7-0a298ea10715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=0.001, epsilon = 0.2, memory_size=2000, batch_size = 50)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train10.mp4'))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/100 | Loss 0.0411 | Win/lose count 7.5/8.0 (-0.5)\n",
            "Epoch 001/100 | Loss 0.0217 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 002/100 | Loss 0.0342 | Win/lose count 5.0/6.0 (-1.0)\n",
            "Epoch 003/100 | Loss 0.0270 | Win/lose count 8.0/11.0 (-3.0)\n",
            "Epoch 004/100 | Loss 0.0356 | Win/lose count 9.5/6.0 (3.5)\n",
            "Epoch 005/100 | Loss 0.0272 | Win/lose count 13.5/2.0 (11.5)\n",
            "Epoch 006/100 | Loss 0.0437 | Win/lose count 8.0/5.0 (3.0)\n",
            "Epoch 007/100 | Loss 0.0426 | Win/lose count 14.5/8.0 (6.5)\n",
            "Epoch 008/100 | Loss 0.0434 | Win/lose count 18.0/12.0 (6.0)\n",
            "Epoch 009/100 | Loss 0.0532 | Win/lose count 15.0/3.0 (12.0)\n",
            "Epoch 010/100 | Loss 0.0289 | Win/lose count 13.5/11.0 (2.5)\n",
            "Epoch 011/100 | Loss 0.0414 | Win/lose count 11.5/10.0 (1.5)\n",
            "Epoch 012/100 | Loss 0.0488 | Win/lose count 20.0/13.0 (7.0)\n",
            "Epoch 013/100 | Loss 0.0419 | Win/lose count 21.5/6.0 (15.5)\n",
            "Epoch 014/100 | Loss 0.0471 | Win/lose count 17.0/8.0 (9.0)\n",
            "Epoch 015/100 | Loss 0.0408 | Win/lose count 20.5/6.0 (14.5)\n",
            "Epoch 016/100 | Loss 0.0377 | Win/lose count 20.0/15.0 (5.0)\n",
            "Epoch 017/100 | Loss 0.0360 | Win/lose count 21.5/10.0 (11.5)\n",
            "Epoch 018/100 | Loss 0.0306 | Win/lose count 23.0/11.0 (12.0)\n",
            "Epoch 019/100 | Loss 0.0286 | Win/lose count 17.0/8.0 (9.0)\n",
            "Epoch 020/100 | Loss 0.0289 | Win/lose count 10.5/11.0 (-0.5)\n",
            "Epoch 021/100 | Loss 0.0374 | Win/lose count 21.0/14.0 (7.0)\n",
            "Epoch 022/100 | Loss 0.0319 | Win/lose count 19.0/18.0 (1.0)\n",
            "Epoch 023/100 | Loss 0.0333 | Win/lose count 15.0/8.0 (7.0)\n",
            "Epoch 024/100 | Loss 0.0326 | Win/lose count 10.0/6.0 (4.0)\n",
            "Epoch 025/100 | Loss 0.0350 | Win/lose count 26.5/7.0 (19.5)\n",
            "Epoch 026/100 | Loss 0.0287 | Win/lose count 21.5/7.0 (14.5)\n",
            "Epoch 027/100 | Loss 0.0249 | Win/lose count 7.0/8.0 (-1.0)\n",
            "Epoch 028/100 | Loss 0.0375 | Win/lose count 17.5/15.0 (2.5)\n",
            "Epoch 029/100 | Loss 0.0295 | Win/lose count 19.5/10.0 (9.5)\n",
            "Epoch 030/100 | Loss 0.0365 | Win/lose count 18.5/7.0 (11.5)\n",
            "Epoch 031/100 | Loss 0.0364 | Win/lose count 23.5/12.0 (11.5)\n",
            "Epoch 032/100 | Loss 0.0390 | Win/lose count 19.0/9.0 (10.0)\n",
            "Epoch 033/100 | Loss 0.0338 | Win/lose count 12.5/12.0 (0.5)\n",
            "Epoch 034/100 | Loss 0.0395 | Win/lose count 15.5/10.0 (5.5)\n",
            "Epoch 035/100 | Loss 0.0224 | Win/lose count 21.0/10.0 (11.0)\n",
            "Epoch 036/100 | Loss 0.0296 | Win/lose count 12.5/12.0 (0.5)\n",
            "Epoch 037/100 | Loss 0.0388 | Win/lose count 20.5/10.0 (10.5)\n",
            "Epoch 038/100 | Loss 0.0242 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 039/100 | Loss 0.0395 | Win/lose count 13.5/7.0 (6.5)\n",
            "Epoch 040/100 | Loss 0.0262 | Win/lose count 16.5/5.0 (11.5)\n",
            "Epoch 041/100 | Loss 0.0363 | Win/lose count 20.5/10.0 (10.5)\n",
            "Epoch 042/100 | Loss 0.0434 | Win/lose count 8.0/5.0 (3.0)\n",
            "Epoch 043/100 | Loss 0.0377 | Win/lose count 15.0/14.0 (1.0)\n",
            "Epoch 044/100 | Loss 0.0474 | Win/lose count 18.0/15.0 (3.0)\n",
            "Epoch 045/100 | Loss 0.0289 | Win/lose count 18.5/10.0 (8.5)\n",
            "Epoch 046/100 | Loss 0.0370 | Win/lose count 13.0/7.0 (6.0)\n",
            "Epoch 047/100 | Loss 0.0471 | Win/lose count 7.0/13.0 (-6.0)\n",
            "Epoch 048/100 | Loss 0.0236 | Win/lose count 16.0/8.0 (8.0)\n",
            "Epoch 049/100 | Loss 0.0273 | Win/lose count 16.5/7.0 (9.5)\n",
            "Epoch 050/100 | Loss 0.0476 | Win/lose count 17.0/12.0 (5.0)\n",
            "Epoch 051/100 | Loss 0.0319 | Win/lose count 18.5/13.0 (5.5)\n",
            "Epoch 052/100 | Loss 0.0267 | Win/lose count 21.5/17.0 (4.5)\n",
            "Epoch 053/100 | Loss 0.0388 | Win/lose count 11.5/6.0 (5.5)\n",
            "Epoch 054/100 | Loss 0.0294 | Win/lose count 11.5/14.0 (-2.5)\n",
            "Epoch 055/100 | Loss 0.0434 | Win/lose count 18.0/15.0 (3.0)\n",
            "Epoch 056/100 | Loss 0.0414 | Win/lose count 15.0/12.0 (3.0)\n",
            "Epoch 057/100 | Loss 0.0357 | Win/lose count 14.5/5.0 (9.5)\n",
            "Epoch 058/100 | Loss 0.0347 | Win/lose count 14.0/14.0 (0.0)\n",
            "Epoch 059/100 | Loss 0.0395 | Win/lose count 13.5/13.0 (0.5)\n",
            "Epoch 060/100 | Loss 0.0354 | Win/lose count 13.0/5.0 (8.0)\n",
            "Epoch 061/100 | Loss 0.0346 | Win/lose count 9.5/8.0 (1.5)\n",
            "Epoch 062/100 | Loss 0.0278 | Win/lose count 18.5/12.0 (6.5)\n",
            "Epoch 063/100 | Loss 0.0445 | Win/lose count 18.5/12.0 (6.5)\n",
            "Epoch 064/100 | Loss 0.0291 | Win/lose count 18.0/11.0 (7.0)\n",
            "Epoch 065/100 | Loss 0.0267 | Win/lose count 20.0/14.0 (6.0)\n",
            "Epoch 066/100 | Loss 0.0431 | Win/lose count 18.0/13.0 (5.0)\n",
            "Epoch 067/100 | Loss 0.0304 | Win/lose count 17.0/13.0 (4.0)\n",
            "Epoch 068/100 | Loss 0.0294 | Win/lose count 8.0/8.0 (0.0)\n",
            "Epoch 069/100 | Loss 0.0446 | Win/lose count 15.0/12.0 (3.0)\n",
            "Epoch 070/100 | Loss 0.0278 | Win/lose count 13.5/6.0 (7.5)\n",
            "Epoch 071/100 | Loss 0.0284 | Win/lose count 18.5/7.0 (11.5)\n",
            "Epoch 072/100 | Loss 0.0451 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 073/100 | Loss 0.0307 | Win/lose count 18.0/5.0 (13.0)\n",
            "Epoch 074/100 | Loss 0.0317 | Win/lose count 13.0/12.0 (1.0)\n",
            "Epoch 075/100 | Loss 0.0367 | Win/lose count 10.0/15.0 (-5.0)\n",
            "Epoch 076/100 | Loss 0.0222 | Win/lose count 13.0/9.0 (4.0)\n",
            "Epoch 077/100 | Loss 0.0267 | Win/lose count 16.0/9.0 (7.0)\n",
            "Epoch 078/100 | Loss 0.0359 | Win/lose count 15.0/10.0 (5.0)\n",
            "Epoch 079/100 | Loss 0.0455 | Win/lose count 17.0/3.0 (14.0)\n",
            "Epoch 080/100 | Loss 0.0318 | Win/lose count 22.0/11.0 (11.0)\n",
            "Epoch 081/100 | Loss 0.0247 | Win/lose count 14.5/10.0 (4.5)\n",
            "Epoch 082/100 | Loss 0.0345 | Win/lose count 14.0/10.0 (4.0)\n",
            "Epoch 083/100 | Loss 0.0423 | Win/lose count 13.0/8.0 (5.0)\n",
            "Epoch 084/100 | Loss 0.0278 | Win/lose count 14.5/6.0 (8.5)\n",
            "Epoch 085/100 | Loss 0.0273 | Win/lose count 19.5/8.0 (11.5)\n",
            "Epoch 086/100 | Loss 0.0357 | Win/lose count 20.0/15.0 (5.0)\n",
            "Epoch 087/100 | Loss 0.0272 | Win/lose count 11.5/9.0 (2.5)\n",
            "Epoch 088/100 | Loss 0.0306 | Win/lose count 13.0/9.0 (4.0)\n",
            "Epoch 089/100 | Loss 0.0284 | Win/lose count 15.5/7.0 (8.5)\n",
            "Epoch 090/100 | Loss 0.0295 | Win/lose count 9.0/9.0 (0.0)\n",
            "Epoch 091/100 | Loss 0.0498 | Win/lose count 9.5/15.0 (-5.5)\n",
            "Epoch 092/100 | Loss 0.0233 | Win/lose count 20.0/8.0 (12.0)\n",
            "Epoch 093/100 | Loss 0.0515 | Win/lose count 15.0/12.0 (3.0)\n",
            "Epoch 094/100 | Loss 0.0546 | Win/lose count 21.5/14.0 (7.5)\n",
            "Epoch 095/100 | Loss 0.0339 | Win/lose count 19.0/15.0 (4.0)\n",
            "Epoch 096/100 | Loss 0.0449 | Win/lose count 12.0/13.0 (-1.0)\n",
            "Epoch 097/100 | Loss 0.0269 | Win/lose count 16.0/15.0 (1.0)\n",
            "Epoch 098/100 | Loss 0.0295 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 099/100 | Loss 0.0286 | Win/lose count 9.0/8.0 (1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv5ciULnQB0F",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWYRXahcQB0K",
        "colab_type": "code",
        "outputId": "82d29e34-ccb0-4f7f-c4b9-5e491cdecf21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.2, memory_size=2000, batch_size = 50)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.2, memory_size=2000, batch_size = 50)\n",
        "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 9.0/6.0. Average score (3.0)\n",
            "Win/lose count 17.0/14.0. Average score (3.0)\n",
            "Win/lose count 15.5/9.0. Average score (4.166666666666667)\n",
            "Win/lose count 19.5/13.0. Average score (4.75)\n",
            "Win/lose count 13.5/16.0. Average score (3.3)\n",
            "Win/lose count 9.0/8.0. Average score (2.9166666666666665)\n",
            "Win/lose count 14.0/11.0. Average score (2.9285714285714284)\n",
            "Win/lose count 5.0/8.0. Average score (2.1875)\n",
            "Win/lose count 18.5/7.0. Average score (3.2222222222222223)\n",
            "Win/lose count 18.5/7.0. Average score (4.05)\n",
            "Final score: 4.05\n",
            "Test of the FC\n",
            "Win/lose count 4.0/4.0. Average score (0.0)\n",
            "Win/lose count 8.5/1.0. Average score (3.75)\n",
            "Win/lose count 13.5/6.0. Average score (5.0)\n",
            "Win/lose count 10.0/1.0. Average score (6.0)\n",
            "Win/lose count 10.5/6.0. Average score (5.7)\n",
            "Win/lose count 4.5/6.0. Average score (4.5)\n",
            "Win/lose count 11.0/3.0. Average score (5.0)\n",
            "Win/lose count 4.0/1.0. Average score (4.75)\n",
            "Win/lose count 7.0/3.0. Average score (4.666666666666667)\n",
            "Win/lose count 10.5/6.0. Average score (4.65)\n",
            "Final score: 4.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBhkElK9QB0d",
        "colab_type": "code",
        "outputId": "bfec181d-30f9-429e-c1bf-40632efacaf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('cnn_test9.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr6Tip7oQB02",
        "colab_type": "code",
        "outputId": "179ef9fa-f95a-4a4e-83e8-6d18cc910248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('fc_test9.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QArJPNdWQB1W",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHSPRuPZQB1b",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH0OOd_UQB1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "    r = 0.9\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "\n",
        "        agent.reduce_epsilon(r)\n",
        "          \n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        \n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state, train=True)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "            \n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-loss\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "    def set_time(self, new_t):\n",
        "        self.t = new_t\n",
        "\n",
        "    def act(self, action, train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        #I changed the following line\n",
        "        self.position[:,-2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "\n",
        "        # You will have to change n_state to 3 because you will use one more layer!\n",
        "        reward = 0\n",
        "        # we update a loss if we already visited\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "\n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        \n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        #I changed the following line\n",
        "        self.position[:, -2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-ollllvQB10",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01d1a5e5-6a22-4ded-88fb-28c6a70d8e99"
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=0.001, epsilon = 0.3, memory_size=2000, batch_size = 32, n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/100 | Loss 0.0526 | Win/lose count 14.0/28.000000000000085 (-14.000000000000085)\n",
            "Epoch 001/100 | Loss 0.0510 | Win/lose count 9.5/22.50000000000007 (-13.000000000000071)\n",
            "Epoch 002/100 | Loss 0.0512 | Win/lose count 26.5/20.00000000000002 (6.499999999999979)\n",
            "Epoch 003/100 | Loss 0.0478 | Win/lose count 22.5/21.40000000000005 (1.0999999999999517)\n",
            "Epoch 004/100 | Loss 0.0605 | Win/lose count 17.5/16.19999999999997 (1.3000000000000291)\n",
            "Epoch 005/100 | Loss 0.0668 | Win/lose count 25.0/22.80000000000001 (2.1999999999999886)\n",
            "Epoch 006/100 | Loss 0.0355 | Win/lose count 20.5/23.300000000000043 (-2.8000000000000433)\n",
            "Epoch 007/100 | Loss 0.0557 | Win/lose count 22.0/17.299999999999997 (4.700000000000003)\n",
            "Epoch 008/100 | Loss 0.0543 | Win/lose count 15.0/20.900000000000023 (-5.9000000000000234)\n",
            "Epoch 009/100 | Loss 0.0490 | Win/lose count 25.0/18.700000000000006 (6.299999999999994)\n",
            "Epoch 010/100 | Loss 0.0348 | Win/lose count 24.0/22.400000000000063 (1.5999999999999375)\n",
            "Epoch 011/100 | Loss 0.0422 | Win/lose count 27.5/20.300000000000043 (7.199999999999957)\n",
            "Epoch 012/100 | Loss 0.0424 | Win/lose count 25.5/22.80000000000005 (2.6999999999999496)\n",
            "Epoch 013/100 | Loss 0.0558 | Win/lose count 25.0/18.6 (6.399999999999999)\n",
            "Epoch 014/100 | Loss 0.0629 | Win/lose count 28.0/22.500000000000053 (5.499999999999947)\n",
            "Epoch 015/100 | Loss 0.0535 | Win/lose count 19.5/18.49999999999999 (1.0000000000000107)\n",
            "Epoch 016/100 | Loss 0.0365 | Win/lose count 15.0/19.599999999999994 (-4.599999999999994)\n",
            "Epoch 017/100 | Loss 0.0608 | Win/lose count 23.5/23.10000000000005 (0.39999999999994884)\n",
            "Epoch 018/100 | Loss 0.0638 | Win/lose count 17.5/21.400000000000006 (-3.9000000000000057)\n",
            "Epoch 019/100 | Loss 0.0433 | Win/lose count 18.0/23.100000000000033 (-5.100000000000033)\n",
            "Epoch 020/100 | Loss 0.0315 | Win/lose count 24.0/22.500000000000025 (1.4999999999999751)\n",
            "Epoch 021/100 | Loss 0.0574 | Win/lose count 18.5/19.40000000000002 (-0.9000000000000199)\n",
            "Epoch 022/100 | Loss 0.0387 | Win/lose count 24.0/20.300000000000008 (3.699999999999992)\n",
            "Epoch 023/100 | Loss 0.0805 | Win/lose count 19.0/22.200000000000028 (-3.2000000000000277)\n",
            "Epoch 024/100 | Loss 0.0637 | Win/lose count 23.0/18.39999999999999 (4.6000000000000085)\n",
            "Epoch 025/100 | Loss 0.0647 | Win/lose count 8.0/23.60000000000007 (-15.600000000000069)\n",
            "Epoch 026/100 | Loss 0.0443 | Win/lose count 10.5/24.90000000000004 (-14.400000000000041)\n",
            "Epoch 027/100 | Loss 0.0543 | Win/lose count 11.5/19.40000000000001 (-7.900000000000009)\n",
            "Epoch 028/100 | Loss 0.0595 | Win/lose count 14.0/17.699999999999985 (-3.699999999999985)\n",
            "Epoch 029/100 | Loss 0.0360 | Win/lose count 18.0/17.39999999999998 (0.6000000000000192)\n",
            "Epoch 030/100 | Loss 0.0602 | Win/lose count 16.0/21.60000000000006 (-5.600000000000058)\n",
            "Epoch 031/100 | Loss 0.0666 | Win/lose count 20.5/21.200000000000056 (-0.7000000000000561)\n",
            "Epoch 032/100 | Loss 0.0533 | Win/lose count 18.0/20.20000000000003 (-2.2000000000000313)\n",
            "Epoch 033/100 | Loss 0.0426 | Win/lose count 15.0/17.999999999999993 (-2.999999999999993)\n",
            "Epoch 034/100 | Loss 0.0521 | Win/lose count 17.5/24.600000000000048 (-7.100000000000048)\n",
            "Epoch 035/100 | Loss 0.0657 | Win/lose count 16.5/19.200000000000017 (-2.700000000000017)\n",
            "Epoch 036/100 | Loss 0.0598 | Win/lose count 20.0/18.6 (1.3999999999999986)\n",
            "Epoch 037/100 | Loss 0.0631 | Win/lose count 16.5/17.79999999999999 (-1.29999999999999)\n",
            "Epoch 038/100 | Loss 0.0727 | Win/lose count 18.5/22.199999999999996 (-3.6999999999999957)\n",
            "Epoch 039/100 | Loss 0.0490 | Win/lose count 16.0/22.000000000000064 (-6.000000000000064)\n",
            "Epoch 040/100 | Loss 0.0650 | Win/lose count 11.0/19.300000000000008 (-8.300000000000008)\n",
            "Epoch 041/100 | Loss 0.0720 | Win/lose count 22.0/19.20000000000002 (2.7999999999999794)\n",
            "Epoch 042/100 | Loss 0.0586 | Win/lose count 21.0/27.600000000000023 (-6.600000000000023)\n",
            "Epoch 043/100 | Loss 0.0486 | Win/lose count 14.5/19.900000000000016 (-5.400000000000016)\n",
            "Epoch 044/100 | Loss 0.0711 | Win/lose count 20.5/20.30000000000004 (0.1999999999999602)\n",
            "Epoch 045/100 | Loss 0.0566 | Win/lose count 12.0/15.79999999999996 (-3.79999999999996)\n",
            "Epoch 046/100 | Loss 0.0484 | Win/lose count 21.0/22.400000000000006 (-1.4000000000000057)\n",
            "Epoch 047/100 | Loss 0.0524 | Win/lose count 16.0/19.300000000000015 (-3.300000000000015)\n",
            "Epoch 048/100 | Loss 0.0714 | Win/lose count 12.0/17.499999999999986 (-5.499999999999986)\n",
            "Epoch 049/100 | Loss 0.0561 | Win/lose count 17.0/16.29999999999996 (0.7000000000000384)\n",
            "Epoch 050/100 | Loss 0.0651 | Win/lose count 8.5/21.700000000000042 (-13.200000000000042)\n",
            "Epoch 051/100 | Loss 0.0741 | Win/lose count 12.0/18.3 (-6.300000000000001)\n",
            "Epoch 052/100 | Loss 0.0508 | Win/lose count 19.0/17.799999999999994 (1.2000000000000064)\n",
            "Epoch 053/100 | Loss 0.0597 | Win/lose count 24.0/15.099999999999968 (8.900000000000032)\n",
            "Epoch 054/100 | Loss 0.0477 | Win/lose count 13.0/18.300000000000004 (-5.300000000000004)\n",
            "Epoch 055/100 | Loss 0.0447 | Win/lose count 18.0/22.00000000000002 (-4.000000000000021)\n",
            "Epoch 056/100 | Loss 0.0355 | Win/lose count 14.5/19.20000000000001 (-4.70000000000001)\n",
            "Epoch 057/100 | Loss 0.0631 | Win/lose count 17.0/17.699999999999985 (-0.6999999999999851)\n",
            "Epoch 058/100 | Loss 0.0768 | Win/lose count 4.5/19.80000000000001 (-15.300000000000011)\n",
            "Epoch 059/100 | Loss 0.0366 | Win/lose count 14.5/23.10000000000008 (-8.60000000000008)\n",
            "Epoch 060/100 | Loss 0.0595 | Win/lose count 19.0/25.10000000000007 (-6.100000000000069)\n",
            "Epoch 061/100 | Loss 0.0536 | Win/lose count 21.5/20.10000000000003 (1.3999999999999702)\n",
            "Epoch 062/100 | Loss 0.0581 | Win/lose count 17.5/18.500000000000014 (-1.0000000000000142)\n",
            "Epoch 063/100 | Loss 0.0442 | Win/lose count 4.5/18.29999999999999 (-13.79999999999999)\n",
            "Epoch 064/100 | Loss 0.0528 | Win/lose count 6.5/19.70000000000001 (-13.20000000000001)\n",
            "Epoch 065/100 | Loss 0.0501 | Win/lose count 13.0/20.900000000000038 (-7.900000000000038)\n",
            "Epoch 066/100 | Loss 0.0569 | Win/lose count 17.5/17.49999999999999 (1.0658141036401503e-14)\n",
            "Epoch 067/100 | Loss 0.0525 | Win/lose count 14.0/22.600000000000072 (-8.600000000000072)\n",
            "Epoch 068/100 | Loss 0.0671 | Win/lose count 13.0/17.69999999999998 (-4.6999999999999815)\n",
            "Epoch 069/100 | Loss 0.0612 | Win/lose count 3.5/21.30000000000004 (-17.80000000000004)\n",
            "Epoch 070/100 | Loss 0.0376 | Win/lose count 23.5/18.70000000000002 (4.799999999999979)\n",
            "Epoch 071/100 | Loss 0.0578 | Win/lose count 25.5/20.1 (5.399999999999999)\n",
            "Epoch 072/100 | Loss 0.0465 | Win/lose count 16.5/21.400000000000052 (-4.900000000000052)\n",
            "Epoch 073/100 | Loss 0.0590 | Win/lose count 5.5/19.80000000000001 (-14.300000000000011)\n",
            "Epoch 074/100 | Loss 0.0620 | Win/lose count 6.0/19.100000000000005 (-13.100000000000005)\n",
            "Epoch 075/100 | Loss 0.0359 | Win/lose count 21.5/16.599999999999984 (4.900000000000016)\n",
            "Epoch 076/100 | Loss 0.0666 | Win/lose count 13.5/17.39999999999998 (-3.899999999999981)\n",
            "Epoch 077/100 | Loss 0.0606 | Win/lose count 24.5/20.200000000000003 (4.299999999999997)\n",
            "Epoch 078/100 | Loss 0.0566 | Win/lose count 10.5/22.499999999999982 (-11.999999999999982)\n",
            "Epoch 079/100 | Loss 0.0681 | Win/lose count 20.0/22.100000000000065 (-2.1000000000000654)\n",
            "Epoch 080/100 | Loss 0.0544 | Win/lose count 11.5/19.30000000000001 (-7.800000000000011)\n",
            "Epoch 081/100 | Loss 0.0579 | Win/lose count 7.0/17.999999999999986 (-10.999999999999986)\n",
            "Epoch 082/100 | Loss 0.0450 | Win/lose count 13.0/17.69999999999998 (-4.6999999999999815)\n",
            "Epoch 083/100 | Loss 0.0564 | Win/lose count 9.5/21.70000000000005 (-12.200000000000049)\n",
            "Epoch 084/100 | Loss 0.0492 | Win/lose count 14.0/18.800000000000008 (-4.800000000000008)\n",
            "Epoch 085/100 | Loss 0.0535 | Win/lose count 7.0/19.900000000000013 (-12.900000000000013)\n",
            "Epoch 086/100 | Loss 0.0593 | Win/lose count 10.5/17.599999999999984 (-7.099999999999984)\n",
            "Epoch 087/100 | Loss 0.0490 | Win/lose count 8.0/17.39999999999998 (-9.39999999999998)\n",
            "Epoch 088/100 | Loss 0.0489 | Win/lose count 3.0/18.799999999999997 (-15.799999999999997)\n",
            "Epoch 089/100 | Loss 0.0421 | Win/lose count 17.0/16.29999999999997 (0.7000000000000313)\n",
            "Epoch 090/100 | Loss 0.0374 | Win/lose count 19.5/18.200000000000003 (1.2999999999999972)\n",
            "Epoch 091/100 | Loss 0.0648 | Win/lose count 6.5/19.700000000000017 (-13.200000000000017)\n",
            "Epoch 092/100 | Loss 0.0339 | Win/lose count 11.0/19.200000000000014 (-8.200000000000014)\n",
            "Epoch 093/100 | Loss 0.0739 | Win/lose count 21.0/16.499999999999964 (4.5000000000000355)\n",
            "Epoch 094/100 | Loss 0.0540 | Win/lose count 14.5/22.19999999999999 (-7.699999999999989)\n",
            "Epoch 095/100 | Loss 0.0524 | Win/lose count 4.0/18.29999999999999 (-14.29999999999999)\n",
            "Epoch 096/100 | Loss 0.0641 | Win/lose count 11.5/17.89999999999999 (-6.3999999999999915)\n",
            "Epoch 097/100 | Loss 0.0524 | Win/lose count 9.5/17.499999999999982 (-7.999999999999982)\n",
            "Epoch 098/100 | Loss 0.0453 | Win/lose count 20.0/20.600000000000048 (-0.6000000000000476)\n",
            "Epoch 099/100 | Loss 0.0748 | Win/lose count 17.5/16.799999999999972 (0.7000000000000277)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nuc9mfLQB2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "6cd59442-45be-4e64-e82c-8abcd5cf0dcb"
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore9.mp4'))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 3.5/0. Average score (3.5)\n",
            "Win/lose count 2.0/0. Average score (2.75)\n",
            "Win/lose count 10.5/3.0. Average score (4.333333333333333)\n",
            "Win/lose count 13.0/3.0. Average score (5.75)\n",
            "Win/lose count 3.0/1.0. Average score (5.0)\n",
            "Win/lose count 5.5/4.0. Average score (4.416666666666667)\n",
            "Win/lose count 6.0/3.0. Average score (4.214285714285714)\n",
            "Win/lose count 3.0/0. Average score (4.0625)\n",
            "Win/lose count 0.5/0. Average score (3.6666666666666665)\n",
            "Win/lose count 6.0/2.0. Average score (3.7)\n",
            "Final score: 3.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVc2EoCYQB2Z",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctPaRWfeQB2e",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMpT26oIQB2k",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}